{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zstandard\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import logging.handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/albertvong/Library/CloudStorage/OneDrive-NorthwesternUniversity/Github Coding Stuff/Reddit NBA Upvote Predictor'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define input and output file names\n",
    "input_file = os.getcwd() + '/reddit/subreddits/nba_submissions.zst'\n",
    "# put the name or path to the output file. The file extension from below will be added automatically\n",
    "output_file = os.getcwd() +'/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/albertvong/Library/CloudStorage/OneDrive-NorthwesternUniversity/Github Coding Stuff/Reddit NBA Upvote Predictoroutput'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_format = \"txt\"\n",
    "# The filename from the torrent has which type it is, but you'll need to change this if you removed that from the filename\n",
    "is_submission = \"submission\" in input_file\n",
    "\n",
    "# Only output items between these two dates\n",
    "from_date = datetime.strptime(\"2019-10-01\", \"%Y-%m-%d\")\n",
    "to_date = datetime.strptime(\"2020-06-01\", \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up logging\n",
    "\n",
    "log = logging.getLogger(\"bot\")\n",
    "log.setLevel(logging.INFO)\n",
    "log_formatter = logging.Formatter('%(asctime)s - %(levelname)s: %(message)s')\n",
    "log_str_handler = logging.StreamHandler()\n",
    "log_str_handler.setFormatter(log_formatter)\n",
    "log.addHandler(log_str_handler)\n",
    "if not os.path.exists(\"logs\"):\n",
    "\tos.makedirs(\"logs\")\n",
    "log_file_handler = logging.handlers.RotatingFileHandler(os.path.join(\"logs\", \"bot.log\"), maxBytes=1024*1024*16, backupCount=5)\n",
    "log_file_handler.setFormatter(log_formatter)\n",
    "log.addHandler(log_file_handler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions for reading from zst json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_line_zst(handle, line):\n",
    "\thandle.write(line.encode('utf-8'))\n",
    "\thandle.write(\"\\n\".encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_line_json(handle, obj):\n",
    "\thandle.write(json.dumps(obj))\n",
    "\thandle.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_line_csv(writer, obj, is_submission):\n",
    "\toutput_list = []\n",
    "\toutput_list.append(str(obj['score']))\n",
    "\toutput_list.append(datetime.fromtimestamp(obj['created_utc']).strftime(\"%Y-%m-%d\"))\n",
    "\tif is_submission:\n",
    "\t\toutput_list.append(obj['title'])\n",
    "\toutput_list.append(f\"u/{obj['author']}\")\n",
    "\toutput_list.append(f\"https://www.reddit.com{obj['permalink']}\")\n",
    "\tif is_submission:\n",
    "\t\tif obj['is_self']:\n",
    "\t\t\tif 'selftext' in obj:\n",
    "\t\t\t\toutput_list.append(obj['selftext'])\n",
    "\t\t\telse:\n",
    "\t\t\t\toutput_list.append(\"\")\n",
    "\t\telse:\n",
    "\t\t\toutput_list.append(obj['url'])\n",
    "\telse:\n",
    "\t\toutput_list.append(obj['body'])\n",
    "\twriter.writerow(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_decode(reader, chunk_size, max_window_size, previous_chunk=None, bytes_read=0):\n",
    "\tchunk = reader.read(chunk_size)\n",
    "\tbytes_read += chunk_size\n",
    "\tif previous_chunk is not None:\n",
    "\t\tchunk = previous_chunk + chunk\n",
    "\ttry:\n",
    "\t\treturn chunk.decode()\n",
    "\texcept UnicodeDecodeError:\n",
    "\t\tif bytes_read > max_window_size:\n",
    "\t\t\traise UnicodeError(f\"Unable to decode frame after reading {bytes_read:,} bytes\")\n",
    "\t\tlog.info(f\"Decoding error with {bytes_read:,} bytes, reading another chunk\")\n",
    "\t\treturn read_and_decode(reader, chunk_size, max_window_size, chunk, bytes_read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines_zst(file_name):\n",
    "\twith open(file_name, 'rb') as file_handle:\n",
    "\t\tbuffer = ''\n",
    "\t\treader = zstandard.ZstdDecompressor(max_window_size=2**31).stream_reader(file_handle)\n",
    "\t\twhile True:\n",
    "\t\t\tchunk = read_and_decode(reader, 2**27, (2**29) * 2)\n",
    "\n",
    "\t\t\tif not chunk:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tlines = (buffer + chunk).split(\"\\n\")\n",
    "\n",
    "\t\t\tfor line in lines[:-1]:\n",
    "\t\t\t\tyield line.strip(), file_handle.tell()\n",
    "\n",
    "\t\t\tbuffer = lines[-1]\n",
    "\n",
    "\t\treader.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for fields, values and exact match\n",
    "field = 'score'\n",
    "score_thresh = 100 #Field threshold for number of upvotes\n",
    "exact_match = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 21:47:10,844 - INFO: 2013-05-21 17:25:15 : 100,000 : 0 : 0 : 32,244,450:7%\n",
      "2023-03-25 21:47:11,995 - INFO: 2014-06-03 18:15:19 : 200,000 : 0 : 0 : 48,628,825:11%\n",
      "2023-03-25 21:47:13,119 - INFO: 2015-03-28 01:05:24 : 300,000 : 0 : 0 : 66,717,175:15%\n",
      "2023-03-25 21:47:14,349 - INFO: 2015-12-16 05:44:06 : 400,000 : 0 : 0 : 83,363,700:19%\n",
      "2023-03-25 21:47:15,588 - INFO: 2016-07-07 03:41:53 : 500,000 : 0 : 0 : 101,189,900:23%\n",
      "2023-03-25 21:47:17,044 - INFO: 2017-03-12 21:52:56 : 600,000 : 0 : 0 : 134,220,800:30%\n",
      "2023-03-25 21:47:18,199 - INFO: 2017-07-23 05:13:16 : 700,000 : 0 : 0 : 148,507,975:33%\n",
      "2023-03-25 21:47:19,429 - INFO: 2018-01-01 04:58:26 : 800,000 : 0 : 0 : 161,746,550:36%\n",
      "2023-03-25 21:47:21,004 - INFO: 2018-05-07 04:51:09 : 900,000 : 0 : 0 : 184,422,525:42%\n",
      "2023-03-25 21:47:22,743 - INFO: 2018-08-07 01:09:47 : 1,000,000 : 0 : 0 : 206,574,200:47%\n",
      "2023-03-25 21:47:24,734 - INFO: 2019-01-17 04:10:49 : 1,100,000 : 0 : 0 : 227,546,200:51%\n",
      "2023-03-25 21:47:26,870 - INFO: 2019-05-11 03:35:34 : 1,200,000 : 0 : 0 : 248,518,200:56%\n",
      "2023-03-25 21:47:28,800 - INFO: 2019-07-19 18:15:35 : 1,300,000 : 0 : 0 : 269,359,125:61%\n",
      "2023-03-25 21:47:31,663 - INFO: 2020-01-14 22:43:01 : 1,400,000 : 9,321 : 0 : 298,064,550:67%\n",
      "2023-03-25 21:47:34,338 - INFO: 2020-07-10 02:54:38 : 1,500,000 : 19,435 : 0 : 318,905,475:72%\n",
      "2023-03-25 21:47:36,912 - INFO: 2020-12-30 05:36:24 : 1,600,000 : 19,435 : 0 : 346,955,525:78%\n",
      "2023-03-25 21:47:40,052 - INFO: 2021-06-19 04:05:46 : 1,700,000 : 19,435 : 0 : 376,054,175:85%\n",
      "2023-03-25 21:47:43,570 - INFO: 2022-02-07 23:52:25 : 1,800,000 : 19,435 : 0 : 405,021,750:91%\n",
      "2023-03-25 21:47:47,021 - INFO: 2022-10-15 23:27:48 : 1,900,000 : 19,435 : 0 : 435,300,075:98%\n",
      "2023-03-25 21:47:48,227 - INFO: Complete : 1,930,304 : 19,435 : 0\n"
     ]
    }
   ],
   "source": [
    "output_path = f\"{output_file}.{output_format}\"\n",
    "\n",
    "writer = None\n",
    "if output_format == \"zst\":\n",
    "    handle = zstandard.ZstdCompressor().stream_writer(open(output_path, 'wb'))\n",
    "elif output_format == \"txt\":\n",
    "    handle = open(output_path, 'w', encoding='UTF-8')\n",
    "elif output_format == \"csv\":\n",
    "    handle = open(output_path, 'w', encoding='UTF-8', newline='')\n",
    "    writer = csv.writer(handle)\n",
    "else:\n",
    "    log.error(f\"Unsupported output format {output_format}\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "file_size = os.stat(input_file).st_size\n",
    "file_bytes_processed = 0\n",
    "created = None\n",
    "matched_lines = 0\n",
    "bad_lines = 0\n",
    "total_lines = 0\n",
    "\n",
    "for line, file_bytes_processed in read_lines_zst(input_file):\n",
    "    total_lines += 1\n",
    "    if total_lines % 100000 == 0:\n",
    "        log.info(f\"{created.strftime('%Y-%m-%d %H:%M:%S')} : {total_lines:,} : {matched_lines:,} : {bad_lines:,} : {file_bytes_processed:,}:{(file_bytes_processed / file_size) * 100:.0f}%\")\n",
    "\n",
    "    try:\n",
    "        obj = json.loads(line)\n",
    "        created = datetime.utcfromtimestamp(int(obj['created_utc']))\n",
    "\n",
    "        if created < from_date:\n",
    "            continue\n",
    "        if created > to_date:\n",
    "            continue\n",
    "        \n",
    "        matched = False\n",
    "        score = obj['score']\n",
    "        if score >= score_thresh:\n",
    "            matched = True\n",
    "            \n",
    "        if not matched:\n",
    "            continue\n",
    "        #Run this if you have additional string filters\n",
    "        # field_value = obj[field].lower() #For strings only\n",
    "        # field_value = obj[field]\n",
    "        # matched = False\n",
    "        # for value in values:\n",
    "        #     if exact_match:\n",
    "        #         if value == field_value:\n",
    "        #             matched = True\n",
    "        #             break\n",
    "        #     else:\n",
    "        #         if value in field_value:\n",
    "        #             matched = True\n",
    "        #             break\n",
    "        # if not matched:\n",
    "        #     continue\n",
    "        \n",
    "        #If we fulfilled some of the criteria then we can output this line (which means something has matched)\n",
    "        matched_lines += 1\n",
    "        if output_format == \"zst\":\n",
    "            write_line_zst(handle, line)\n",
    "        elif output_format == \"csv\":\n",
    "            write_line_csv(writer, obj, is_submission)\n",
    "        elif output_format == \"txt\":\n",
    "            write_line_json(handle, obj)\n",
    "    except (KeyError, json.JSONDecodeError) as err:\n",
    "        bad_lines += 1\n",
    "\n",
    "handle.close()\n",
    "log.info(f\"Complete : {total_lines:,} : {matched_lines:,} : {bad_lines:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22782bf086980a597813833627257b8fd0f2ec5b5fb163a3f665d2a9eebd03ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
